{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyRFM\n",
    "__This script is an implementaion of Reflectance Field Mapping as published in ICRA 2023.__\n",
    "\n",
    "This script is designed for readability and flexibility, and runs in a batch mode.  \n",
    "Our C++ implementation demonstrates use of this in a full SLAM system, but this notebook shows only the mapping part.\n",
    "\n",
    "# Usage\n",
    "\n",
    "There are 3 main parts:\n",
    "- *doRFM()* creates a basic reflectance field map, simply rasterizing hits and misses in (x,y,theta) space.\n",
    "- *selectH()* selectively keeps glass by floodfilling RFM and finding connected components with the H shape feature defined in the paper\n",
    "- *classifyReflections()* Removes lidar beams that pass \"through\" a known object and are likely reflected images of something else\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In online mode, these three steps run constantly and interleaved. However a 3D incremental floodfill is unreadable in Python and somewhat slow.  \n",
    "To get the same effect in batch mode, you run the following sequence:\n",
    "\n",
    "    doRFM() -> selectH() -> clasifyReflections() -> doRFM() -> selectH()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Data\n",
    "\n",
    "This code uses input data in a deliberately trivial format. Every lidar observation specifies:\n",
    "\n",
    "- sx,sy : the start of the ray (i.e. lidar sensor center) in the map coordinates \n",
    "- ex,ey : the endpoint of the ray\n",
    "- r, th, i : original range, angle, and intensity reported by the sensor \\[th, i are unused\\]\n",
    "- idx : the identifier of the sensor the ray is from \\[unused\\]\n",
    "- ts : Unix timestamp of the ray \\[unused\\]\n",
    "\n",
    "These are simply dumped (little endian) for every ray to a file, with sizes as specifed in the data loading cell below. Bad rays are indicated by a negative range.\n",
    "\n",
    "Because rays are already expressed in map coodinates there is no need for cross referencing with localization, motion compensation, or other nontrivial coordinate transformations.\n",
    "\n",
    "For our sensor, every 1081 rays corresponds to a whole scan, but you may want to change this for your code. \n",
    "The RFM is quite tolerant of incorrect scan sizes, but assumes a HIT and MISS cannot happen in the same cell within a scan, which preserves tricky corners.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm # progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rayfile = \"/bbb3_glass_eval_111716.rays\"\n",
    "raypath = os.getcwd()+rayfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyperparameter Setting Instructions\n",
    "1. CELLS_PER_M should indicate a cell width less than the max displacement of the robot between scans. \n",
    "   1. Otherwise there may be gaps between adjacent rays in the same direction.\n",
    "2. Theta width should be >= laser angular spacing, and <= min peak half-width (i.e \"beam divergance\") at worst laser plane tilt\n",
    "   1. If you can't satisfy both, mount your laser better, stiffen your suspension, or get a blurrier (higher divergence) laser!\n",
    "3. Max range should be set so max_turn_rate * max_range < cell_width\n",
    "4. Currently, the max distance is hardcoded at 200 cells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYPERPARAMTERs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_spacing = 2*np.pi/360/4 # 1/4 degree spacing from the sensor\n",
    "th_bins = int(np.round(2*np.pi / th_spacing)) \n",
    "W, H = 800,1200\n",
    "\n",
    "\n",
    "bias = 0\n",
    "wide_threshold = 30*np.pi/180 / th_spacing\n",
    "epsl = 1.\n",
    "\n",
    "## Derived constants\n",
    "# w_HIT = 3 # Reduce to 1 if known no motion\n",
    "# w_MISS = 1 \n",
    "# REF_BLOCK_THRESH = w_MISS/(w_MISS+w_HIT) # the theoretical way. Fraction of hits to total that means we have a reflective voxel\n",
    "REF_BLOCK_THRESH = 0.3 # this is a good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Large persistent memory blocks. \n",
    "HIT = np.zeros((W,H,th_bins),'int16')\n",
    "MISS = np.zeros((W,H,th_bins),'int16')\n",
    "RFM = np.zeros((W,H,th_bins),'int8') # -1=TRANSPARENT, 0=UNK, 1=REFLECT\n",
    "RFM_mr = np.zeros((W,H,th_bins),'int8')\n",
    "WIDE = np.zeros((W,H,th_bins),'bool')\n",
    "NARROW = np.zeros((W,H,th_bins),'bool')\n",
    "prerender = np.zeros((W,H),'bool')\n",
    "refl_cache = np.zeros((W,H),'int16')\n",
    "trans_cache = np.zeros((W,H),'int16')\n",
    "OCC = np.zeros((W,H),'int8')\n",
    "\n",
    "vox_refl = np.zeros((W,H,th_bins),'float32')  \n",
    "CLASSIFIED_RFM = np.zeros((W,H,th_bins),'bool')  \n",
    "countvis = np.zeros((W,H),'uint16')\n",
    "counttrans = np.zeros((W,H),'uint16')\n",
    "countratio = np.zeros((W,H),'float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load rays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rays_struct = np.dtype(\n",
    "    [\n",
    "        ('sx', np.float32),\n",
    "        ('sy', np.float32),\n",
    "        ('ex', np.float32),\n",
    "        ('ey', np.float32),\n",
    "        ('r' , np.float32),\n",
    "        ('th', np.float32),\n",
    "        ('i',  np.int32),\n",
    "        ('idx',  np.int32),\n",
    "        ('ts', np.float64), \n",
    "      ])\n",
    "\n",
    "# rays0 = np.memmap(rayfile,rays_struct, 'r',1) # if you want, you can memory map the file.\n",
    "rays0 = np.fromfile(raypath, rays_struct)\n",
    "rays0 = rays0[:int(len(rays0)//1081*1081)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the max extent of the map and transforms\n",
    "\n",
    "keep=(rays0['r']<10000)*(rays0['r']<10000)\n",
    "rays=rays0[keep==1]\n",
    "\n",
    "## Figure out rasterization\n",
    "# Floor of float coords is integer coords\n",
    "# Images are y flipped\n",
    "\n",
    "def homp(T,pts):\n",
    "    tmppts = pts @ T[:-1,:-1].T + T[:-1,-1]\n",
    "    denom = pts @ T[-1:,:-1].T + T[-1,-1]\n",
    "    return tmppts/denom\n",
    "\n",
    "\n",
    "CELLS_PER_M = 20.0\n",
    "print(\"Cell width:\", 1/CELLS_PER_M)\n",
    "\n",
    "formatter = {'float':lambda x:np.format_float_positional(x,precision=2,fractional=True,trim='-',pad_left=8,pad_right=2)}\n",
    "\n",
    "def get_T_px_f_with_extent(rays, debug=False):\n",
    "    # The corners in world space\n",
    "    f_corns = np.array(\n",
    "        [[np.min(rays['ex']),np.min(rays['ey'])],\n",
    "         [np.max(rays['ex']),np.max(rays['ey'])]])\n",
    "    T_pxc_f = np.array(\n",
    "        [[1*CELLS_PER_M, 0             , 0],\n",
    "         [0            , -1*CELLS_PER_M, 0],\n",
    "         [0            , 0             , 1]])\n",
    "    pxc_corns=homp(T_pxc_f,f_corns)\n",
    "    pxc_topleft = np.array([  np.floor(np.min(pxc_corns[:,0])), np.floor(np.min(pxc_corns[:,1]))  ]) #inclusive\n",
    "    pxc_btmright= np.array([  np.floor(np.max(pxc_corns[:,0])), np.floor(np.max(pxc_corns[:,1]))  ]) + 1 #exclusive\n",
    "    pxc_extent = pxc_btmright-pxc_topleft\n",
    "\n",
    "    T_px_f = T_pxc_f.copy()\n",
    "    T_px_f[:-1,-1] = -pxc_topleft\n",
    "\n",
    "    px_corns=homp(T_px_f,f_corns)\n",
    "    px_topleft = np.array([  np.floor(np.min(px_corns[:,0])), np.floor(np.min(px_corns[:,1]))  ]) #inclusive\n",
    "    px_btmright= np.array([  np.floor(np.max(px_corns[:,0])), np.floor(np.max(px_corns[:,1]))  ]) + 1 #exclusive\n",
    "    px_extent = px_btmright-px_topleft\n",
    "\n",
    "    assert (np.all(pxc_extent == px_extent))\n",
    "\n",
    "    if debug:\n",
    "        print(\"fcorns\\n\",f_corns)\n",
    "\n",
    "        for var in ['pxc_corns',\n",
    "                    'pxc_topleft',\n",
    "                    'pxc_btmright',\n",
    "                    'pxc_extent',\n",
    "                    'px_corns',\n",
    "                    'px_topleft',\n",
    "                    'px_btmright',\n",
    "                    'px_extent',\n",
    "                    ]:\n",
    "            print(var+'\\n', eval(var))\n",
    "    return T_px_f, px_extent.astype('int64')\n",
    "\n",
    "keep_for_window=(rays0['r']>0)*(rays0['r']<10)\n",
    "with np.printoptions(formatter=formatter):\n",
    "    T_px_f, px_extent = get_T_px_f_with_extent(rays[keep_for_window], debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert rays to grid coodinates\n",
    "This is just a scaling and offset.  \n",
    "Since we computed the extent of the map in a previous cell, if you want to use a subset of the rays, but keep map extents, do it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debug show input rays\n",
    "# %matplotlib widget\n",
    "# plt.plot(rays0['ex'],rays0['ey'],'b,')\n",
    "\n",
    "\n",
    "# # If you need to edit the rays, but keep extents, do it here\n",
    "# # Example: Slice by endpoint\n",
    "# rays0 = rays0[rays0['ex']>50 ]\n",
    "# rays0 = rays0[rays0['ex']<55 ]\n",
    "# rays0 = rays0[rays0['ey']<23 ]\n",
    "# print(len(rays0))\n",
    "\n",
    "# # Example 2: Slice away a certain number of rays\n",
    "# substart = 0\n",
    "# subend = int(2.0e6)\n",
    "# rays0 = rays0[substart:subend]\n",
    "# rays0 = rays0[:int(len(rays0)//1081*1081)] # Trick to cut off ragged scans to make blocks of length 1081\n",
    "\n",
    "# # Example 3: Slice by time\n",
    "# rays0 = rays0[rays0['ts']< 1479396535.3080368]\n",
    "rays = rays0.copy()\n",
    "\n",
    "print(\"# Rays to map:\", len(rays0))\n",
    "plt.plot(rays0['ex'],rays0['ey'],'k,')\n",
    "plt.plot(rays0['sx'],rays0['sy'],'c,')\n",
    "print(\"Time range to map:\", np.min(rays0['ts']),np.max(rays0['ts']))\n",
    "\n",
    "# convert to [start_cell_x,start_cell_y, d_cell, th] format\n",
    "f_spt = np.vstack((rays['sx'].ravel(),rays['sy'].ravel())).T.copy()\n",
    "f_ept = np.vstack((rays['ex'].ravel(),rays['ey'].ravel())).T.copy()\n",
    "px_spt = homp(T_px_f, f_spt)\n",
    "px_ept = homp(T_px_f, f_ept)\n",
    "px_d = np.sqrt(np.sum((px_ept-px_spt)**2,axis=1))\n",
    "px_th = np.mod(np.arctan2((px_ept-px_spt)[:,1], (px_ept-px_spt)[:,0]),2*np.pi)\n",
    "def get_raster_coords(rays, T_px_f):\n",
    "    # implicit inputs: T_px_f\n",
    "    f_ept = np.vstack((rays['ex'].ravel(),rays['ey'].ravel())).T.copy()\n",
    "    px_coords = homp(T_px_f, f_ept)\n",
    "    px_coords = px_coords.reshape(rays['ex'].shape+(2,))\n",
    "    return px_coords\n",
    "\n",
    "th_spacing = 2*np.pi/360/4\n",
    "\n",
    "outrays = np.vstack([px_spt.T,px_d,px_th/th_spacing])\n",
    "notref = np.ones_like(outrays[0], dtype=bool)\n",
    "\n",
    "# #\n",
    "# plt.plot(px_ept[:,0],px_ept[:,1],'b,')\n",
    "# plt.plot(px_ept[10000:101081,0],px_ept[10000:101081,1],'r,')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RFM\n",
    "The following calculates the basic RFM, accumulating HITs and MISSes. \\\n",
    "It does not account for reflections, and doesn't link up objects (we do that later)\n",
    "\n",
    "Typically runs ~80 scans/second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loclip = np.array([0,0,0]).reshape(3,1)\n",
    "hiclip = (np.array(HIT.shape)-1).reshape(3,1)\n",
    "def quantize(coords):# 3xN\n",
    "    return np.clip(np.floor(coords),loclip,hiclip).astype('int')\n",
    "\n",
    "def quantize4(coords): # 4 pt xy antialiasing samples # 3xN\n",
    "    coords = np.array(coords).T  # Nx3\n",
    "    aa = np.array(((-0.5,-0.5,0.0), (-0.5,0.5,0.0), \n",
    "                  ( 0.5,-0.5,0.0), ( 0.5,0.5,0.0) )) # 4x3\n",
    "    coords4 = aa + coords[:,np.newaxis,:] # N,4,3\n",
    "    coords4= coords4.reshape(-1,3).T\n",
    "    return np.floor(np.clip(coords4,loclip,hiclip)).astype('int')\n",
    "\n",
    "def RFM_update_cell(x,y,th):\n",
    "    # Unused in batch mode! Would update floodfill connected components in non-batch\n",
    "    pass\n",
    "    \n",
    "# Define the accumulate operator, that renders rays\n",
    "def accumulate(rays, notref):\n",
    "    \n",
    "    \n",
    "\n",
    "    # ray has a starting point, distance before it returned, and direction\n",
    "    [x_start, y_start, d, th] = rays\n",
    "    [slope_x, slope_y] = [np.cos(th*th_spacing), np.sin(th*th_spacing)]\n",
    "    \n",
    "    # prerender lets us stop rendering a ray that would go through a HIT\n",
    "    prerender[:,:]=0\n",
    "    xyth = quantize4((x_start[notref] + d[notref]*slope_x[notref], y_start[notref] + d[notref]*slope_y[notref], th[notref]))\n",
    "    prerender[xyth[0],xyth[1]]=1\n",
    "    \n",
    "\n",
    "    # ray has a starting point, distance before it returned, and direction\n",
    "    [x_start, y_start, d, th] = rays\n",
    "    [slope_x, slope_y] = [np.cos(th*th_spacing), np.sin(th*th_spacing)]\n",
    "    \n",
    "    \n",
    "    # Render all MISSES in parallel. Rays stop drawing when past d-epsl from the start\n",
    "    live=np.ones_like(d)\n",
    "    r=np.full_like(d,0)\n",
    "    for r0 in range(0,200):\n",
    "        r[:]=r0\n",
    "        live[r0>=d-epsl]=0\n",
    "        r[live==0]=100000\n",
    "        xyth = quantize((x_start + r*slope_x, y_start + r*slope_y, th))\n",
    "        live*=(prerender[xyth[0],xyth[1]]==0)\n",
    "        MISS[xyth[0],xyth[1],xyth[2]]+=1\n",
    "        RFM_update_cell(xyth[0],xyth[1],xyth[2])\n",
    "    xyth = quantize((x_start[notref] + d[notref]*slope_x[notref], y_start[notref] + d[notref]*slope_y[notref], th[notref]))\n",
    "    HIT[xyth[0],xyth[1],xyth[2]]+=1\n",
    "    RFM_update_cell(xyth[0], xyth[1], xyth[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic RFM doer. \n",
    "def doRFM():\n",
    "    print(\"Building RFM\")\n",
    "    MISS[...] = 0\n",
    "    HIT[...] = 0\n",
    "    arays = outrays.copy()\n",
    "\n",
    "    ls=0\n",
    "    keep=(rays0['r']<10)*(rays0['r']>0)\n",
    "    CHUNK_SIZE = 1081\n",
    "    for s in tqdm(range(CHUNK_SIZE,arays.shape[1]+1,CHUNK_SIZE)):\n",
    "            tmprays=arays[:,ls:s][:,keep[ls:s]]\n",
    "            nrtemp=notref[ls:s][keep[ls:s]]\n",
    "            accumulate(tmprays, nrtemp)\n",
    "            ls=s\n",
    "    plt.imshow(np.sum(MISS,axis=2))\n",
    "    assert np.max(MISS)>0\n",
    "    vox_refl[...] = HIT/(np.float32(0.1)+HIT+MISS) # classify \n",
    "    CLASSIFIED_RFM[...] = vox_refl > REF_BLOCK_THRESH\n",
    "    countvis[...] = np.sum(CLASSIFIED_RFM, axis=2).astype(np.uint16)\n",
    "    counttrans[...] = np.sum((CLASSIFIED_RFM==0)&(MISS>0), axis=2).astype(np.uint16)\n",
    "    countratio[...] = np.float32(1.0*countvis/(countvis+counttrans+0.0000000001))\n",
    "    refl_cache[...] = (countratio > 0.5) | (countvis > 12)  # More reflective than not or a suspiciously wide range of sightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility that unions two sets of labelled data. Used to turn normal flood fill into circular floodfill around theta.\n",
    "def unify_labels(rfmcomps, rfmcomps2):\n",
    "    # unify labels is mostly a wrapper around fuse, but with the optimization that we only try to \n",
    "    # fuse nonzero labels, since we know they're the same\n",
    "    def fuse(A,B):\n",
    "        # Assumes A and B are label matricies with different labels and we need to fuse them\n",
    "        # Any repeated label between the two corresponds\n",
    "        # Assumes that the labels go from 0 to max(max(A),max(B))\n",
    "        # Also assumes all labels in A are <= to the ones in B\n",
    "        assert(np.all(A<=B))\n",
    "  \n",
    "        lookup = np.arange(np.maximum(np.max(A),np.max(B))+1, dtype=np.int32)\n",
    "        np.minimum.at(lookup,B,A) # Bs now lookup the lowest A they connect to, As loopback\n",
    "\n",
    "        B=lookup[B] #Now all Bs are <= A\n",
    "\n",
    "        np.minimum.at(lookup,A,B)\n",
    "        #As lookup the smallest B they connect to, Bs lookup the smallest A or better\n",
    "        B=lookup[lookup[B]] \n",
    "\n",
    "        extr=(A!=B) \n",
    "        remA=A[extr]\n",
    "        remB=B[extr]\n",
    "        if len(remA)==0:\n",
    "            \n",
    "            return B\n",
    "        recur = fuse(remB,remA)\n",
    "        B[extr] = recur\n",
    "        return B\n",
    "    \n",
    "    nz=fuse(rfmcomps[rfmcomps!=0].ravel(),rfmcomps2[rfmcomps2!=0].ravel())\n",
    "    rfmcomps[rfmcomps!=0]=nz\n",
    "    return rfmcomps\n",
    "\n",
    "# fuse(np.array([1,2,2,3,3,4,4]),np.array([5,6,7,7,8,8,9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Reflection Rays\n",
    "Mark the depths where rays try to go through another object. \n",
    "PEN_DEPTH controls this. We set to 30cm to deal with the stupid 20cm short detections that seem to plague our laser.\n",
    "\n",
    "The basic idea is that all rays render MISSes, but only rays that travel less than PEN_DEPTH from the surface can render HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify reflectionness of a ray and clip to a given penetration depth\n",
    "PEN_DEPTH = np.ceil(0.101*CELLS_PER_M)\n",
    "def classify(rays, pen_depth=None):\n",
    "    rays=rays.copy()\n",
    "    if pen_depth is None:\n",
    "        pen_depth = PEN_DEPTH\n",
    "    HACK_FACTOR = 2 # ensure that detected reflections still count as seen through for this distance\n",
    "#     for ray in rays:\n",
    "    # ray has a starting point, distance before it returned, and direction\n",
    "    [x_start, y_start, d, th] = rays\n",
    "    [slope_x, slope_y] = [np.cos(th*th_spacing), np.sin(th*th_spacing)]\n",
    "    \n",
    "    \n",
    "    notref=np.ones_like(d,dtype=bool)\n",
    "    r=np.full_like(d,0)\n",
    "    for r0 in tqdm(range(0,200)):\n",
    "#         print(r0,end=', ')\n",
    "        r[:]=r0\n",
    "        xyth = quantize((x_start + r*slope_x, y_start + r*slope_y, th))\n",
    "        \n",
    "#         if r0>1\n",
    "        stopped=(refl_cache[xyth[0],xyth[1]]!=0)\n",
    "        notrefish = r0 > d[stopped]-pen_depth\n",
    "        notref[stopped] *= notrefish\n",
    "#         print(r0+pen_depth)\n",
    "       \n",
    "        d[stopped]=np.minimum(d[stopped],r0+pen_depth+HACK_FACTOR) \n",
    "        \n",
    "    rays = np.vstack([x_start, y_start, d, th])\n",
    "    return rays, notref\n",
    "\n",
    "\n",
    "# The returned rays now have distances reflecting how far to render them. \n",
    "# If the distance is less than the original, we want to not render the HIT when we rerender\n",
    "# \"notref\" keeps track of which rays should render their endpoint\n",
    "\n",
    "# This operation is ~1/3 the work of the normal RFM render, but I haven't optimized it, so it \n",
    "# runs much slower when the ray list is too big fo the cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function produces a label array rfmcomps, that labels everything that is connected in RFM space, accounting for the wraparound of theta\n",
    "# It works by labelling connected components, rolling Pi around, relabelling, and then merging the resulting label set\n",
    "\n",
    "from scipy.ndimage import label\n",
    "from scipy.ndimage import generate_binary_structure\n",
    "\n",
    "def label_connected_components():\n",
    "    global rfmcomps\n",
    "    vox_refl[...] = HIT/(np.float32(0.1)+HIT+MISS)\n",
    "    structure=generate_binary_structure(3,3)\n",
    "    rfmcomps, count = label(vox_refl>REF_BLOCK_THRESH, structure)\n",
    "\n",
    "    roll_vox_refl=np.roll(vox_refl, int(vox_refl.shape[2]//2), axis=2)\n",
    "    rfmcomps2, count = label(roll_vox_refl>REF_BLOCK_THRESH, structure)\n",
    "    del roll_vox_refl\n",
    "    offset=np.max(rfmcomps)+1\n",
    "    rfmcomps2=np.roll(rfmcomps2, -int(rfmcomps2.shape[2]//2), axis=2)+offset\n",
    "    rfmcomps2[rfmcomps2==offset]=0\n",
    "    rfmcomps = unify_labels(rfmcomps, rfmcomps2)\n",
    "    del rfmcomps2\n",
    "    return rfmcomps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell removes motion from RFM, given a label array for connected components\n",
    "def selectH():\n",
    "    global HIGHLY_VISIBLE\n",
    "    global rfmcomps\n",
    "    global selection_color\n",
    "    rfmcomps = label_connected_components()\n",
    "    HIGHLY_VISIBLE = (countvis>wide_threshold)\n",
    "    selection_color = np.max(rfmcomps)+1\n",
    "\n",
    "    plt.imshow(HIGHLY_VISIBLE.T)\n",
    "\n",
    "    # Build an array that has the selection_color on highly visible items, and the old color on everythng else\n",
    "    rfmcomps2 = (rfmcomps > 0)*HIGHLY_VISIBLE[:,:,np.newaxis]*selection_color\n",
    "    rfmcomps2[rfmcomps2==0]=rfmcomps[rfmcomps2==0]\n",
    "\n",
    "    # # Debug: check the selelection array\n",
    "    # to_show=np.nonzero(rfmcomps2!=rfmcomps2[-3,-3,-3])\n",
    "    # per=np.random.permutation(int(np.max(rfmcomps2))+1)\n",
    "    # %gui qt\n",
    "    # import mayavi.mlab\n",
    "    # mayavi.mlab.points3d(to_show[0], to_show[1], to_show[2],per[rfmcomps2[to_show].astype(int)], colormap='spectral',mode= 'point')\n",
    "\n",
    "    # Flood from the seeds\n",
    "    rfmcomps = unify_labels(rfmcomps, rfmcomps2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we've defined everything, let's run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeprays=(rays0['r']<10)*(rays0['r']>0) # needed in ablations\n",
    "doRFM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.imshow(refl_cache.T)\n",
    "plt.title('Cells that stop rays for reflectance calculations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "selectH()\n",
    "\n",
    "# Selected Cells now have the highest label id.\n",
    "newselcolor=np.max(rfmcomps[HIGHLY_VISIBLE,:])\n",
    "selected = np.sum(rfmcomps==newselcolor,axis=2)\n",
    "\n",
    "# We keep all locations that are selected or have a HIT with no MISS \n",
    "nevermissed = ((np.sum(HIT,axis=2)>0)&(np.sum(MISS,axis=2)==0))\n",
    "allkept = 0.5*nevermissed+selected\n",
    "\n",
    "# Use this for reflection removal calculations, rather than the one acumulated in the basic RFM\n",
    "# Skiping this lets you ablate how the motion removal affects reflection removal\n",
    "refl_cache[...] = (allkept!=0)\n",
    "\n",
    "# Display the result summary so far\n",
    "%matplotlib widget\n",
    "plt.imshow(allkept.T>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize after flood fill\n",
    "%matplotlib widget\n",
    "print(rfmcomps.shape)\n",
    "\n",
    "plt.imshow(np.clip(selected.T,0,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to remove reflections and do it all over again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeprays=(rays0['r']<10)*(rays0['r']>0)\n",
    "\n",
    "# Reflection removal\n",
    "arays,notref = classify(outrays)\n",
    "\n",
    "# Repeat RFM building\n",
    "doRFM()\n",
    "\n",
    "# Repeat motion removal\n",
    "selectH()\n",
    "# Now we're done! everything after this is just display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected Cells now have the highest label id.\n",
    "newselcolor=np.max(rfmcomps[HIGHLY_VISIBLE,:])\n",
    "selected = np.sum(rfmcomps==newselcolor,axis=2)\n",
    "\n",
    "# We keep all locations that are selected or have a HIT with no MISS \n",
    "nevermissed = ((np.sum(HIT,axis=2)>0)&(np.sum(MISS,axis=2)==0))\n",
    "allkept = 0.5*nevermissed+selected\n",
    "\n",
    "# Use this for reflection removal calculations, rather than the one acumulated in the basic RFM\n",
    "# Skiping this lets you ablate how the motion removal affects reflection removal\n",
    "refl_cache[...] = (allkept!=0)\n",
    "\n",
    "# Display the result summary so far\n",
    "%matplotlib widget\n",
    "plt.imshow(allkept.T>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debug\n",
    "# to_show=np.nonzero(rfmcomps!=rfmcomps[-3,-3,-3])\n",
    "# per=np.random.permutation(int(np.max(rfmcomps2))+1)\n",
    "# %gui qt\n",
    "# import mayavi.mlab\n",
    "# mayavi.mlab.close(all=True)\n",
    "# mayavi.mlab.points3d(to_show[0], to_show[1], to_show[2],per[rfmcomps[to_show].astype(int)], colormap='spectral', mode= 'point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Ratio Metric for Occupancy \n",
    "countvis = np.sum(CLASSIFIED_RFM, axis=2).astype(np.uint16)\n",
    "counttrans = np.sum((CLASSIFIED_RFM==0)&(MISS>0), axis=2).astype(np.uint16)\n",
    "countratio = np.float32(1.0*countvis/(countvis+counttrans+0.0000000001))\n",
    "\n",
    "markedrfc = (rfmcomps>0)*countratio[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infofile = str(round(rays0['ts'][0]*1e6))+\"_\"+str(round(rays0['ts'][-1]*1e6))+\".info\"\n",
    "print(\"Saving to:\",infofile)\n",
    "print()\n",
    "\n",
    "original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "\n",
    "with open(infofile, 'w') as f:\n",
    "    sys.stdout = f # Change the standard output to the file we created.\n",
    "    print(\"# Transform between map and pixels (opengl flooring convention):\")\n",
    "    print(\"T_px_f=\",T_px_f.tolist())\n",
    "    print(\"# Image info\")\n",
    "    print(\"W,H,th_bins=\",(W,H,th_bins))\n",
    "    print(\"# Which rays were used:\")\n",
    "    print(\"start_time=\", str(np.min(rays0['ts'])))\n",
    "    print(\"end_time=\", str(np.max(rays0['ts'])))\n",
    "    print(\"# Base dataset:\")\n",
    "    print(\"rayfile=\",str(rayfile))\n",
    "    sys.stdout = original_stdout \n",
    "with open(infofile, 'r') as f:\n",
    "    print(f.read())\n",
    "import cv2\n",
    "\n",
    "def writeim(name, IM):\n",
    "    # storage format is 16 bit unsigned\n",
    "    layers=[IM[:,:,layer] for layer in range(IM.shape[2])]\n",
    "    batches=[np.hstack(layers[off:off+40]) for off in range(0,IM.shape[2],40)]\n",
    "    rearranged = np.vstack(batches)\n",
    "    cv2.imwrite(name,rearranged.astype(np.uint16))\n",
    "writeim(\"MISS.png\", MISS)\n",
    "writeim(\"HIT.png\", HIT)\n",
    "cv2.imwrite(\"refl_cache.png\",refl_cache)\n",
    "cv2.imwrite(\"allkept.png\" , ((allkept>0)*255).astype(np.uint8))\n",
    "countvis = np.sum(CLASSIFIED_RFM, axis=2).astype(np.uint16)\n",
    "counttrans = np.sum((CLASSIFIED_RFM==0)&(MISS>0), axis=2).astype(np.uint16)\n",
    "cv2.imwrite(\"countvis.png\" , countvis)\n",
    "cv2.imwrite(\"counttrans.png\" , counttrans)\n",
    "cv2.imwrite(\"countratio.png\" , (countvis*1.0/(counttrans+countvis)*255).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how we're doing on memory (I have 64GB on the dev machine)\n",
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:20]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
